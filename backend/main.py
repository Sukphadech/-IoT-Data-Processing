import pandas as pd
import logging
from fastapi import FastAPI, Query,Depends, UploadFile, File
from datetime import datetime, timedelta 
from sqlalchemy.orm import Session
from database import SessionLocal, SensorData, engine
from fastapi.middleware.cors import CORSMiddleware
from io import StringIO


# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)
from database import Base
Base.metadata.create_all(bind=engine)

app = FastAPI()

# ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏´‡πâ Frontend ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏ö‡∏ô http://localhost:5173 ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á API ‡πÑ‡∏î‡πâ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Dependency ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á database session
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()



@app.get("/sensor/processed")
def get_cleaned_data(db: Session = Depends(get_db)):
    data = db.query(SensorData).all()
    if not data:
        return {"message": "No data available", "cleaned_data": [], "anomalies": []}

    df = pd.DataFrame([d.__dict__ for d in data])
    df.drop(columns=["_sa_instance_state"], inplace=True, errors="ignore")
    df.drop_duplicates(inplace=True)

    df["timestamp"] = df["timestamp"].apply(lambda x: x.isoformat() + "Z" if isinstance(x, datetime) else None)

    anomalies = detect_anomalies_iqr(df)
    # ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á anomalies ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å cleaned_data
    anomaly_ids = {row["id"] for row in anomalies}
    cleaned_data = df[~df["id"].isin(anomaly_ids)]
    
    cleaned_data = cleaned_data.sort_values(by="timestamp", ascending=True)


    return {
        "cleaned_data": cleaned_data.to_dict(orient="records"),  # ‚úÖ ‡πÉ‡∏ä‡πâ to_dict(orient="records")
        "anomalies": anomalies
    }





# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Anomalies ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ IQR (Interquartile Range)
def detect_anomalies_iqr(df):
    anomalies = []
    for col in ["temperature", "humidity", "air_quality"]:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        anomaly_rows = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        anomalies.extend(anomaly_rows.to_dict(orient="records"))
    
    return anomalies

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()



@app.post("/upload/")
async def upload_file(file: UploadFile = File(...), db: Session = Depends(get_db)):
    try:
        contents = await file.read()
        decoded = contents.decode("utf-8")
        df = pd.read_csv(StringIO(decoded))

        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV
        expected_columns = {"timestamp", "temperature", "humidity", "air_quality"}
        if not expected_columns.issubset(df.columns):
            return {"error": "‚ùå ‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: timestamp, temperature, humidity, air_quality"}

        # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á timestamp ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô datetime
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")

        # ‚úÖ ‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ timestamp ‡πÄ‡∏õ‡πá‡∏ô NaT (‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)
        df = df.dropna(subset=["timestamp"])

        # ‚úÖ ‡∏Å‡∏≥‡∏à‡∏±‡∏î NaN ‡πÉ‡∏ô‡∏Ñ‡πà‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡πÜ
        df.fillna({"temperature": 0, "humidity": 0, "air_quality": 0}, inplace=True)

        # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô SensorData ‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Database
        data_to_insert = [
            SensorData(
                timestamp=row["timestamp"].to_pydatetime(),  # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô datetime
                temperature=row["temperature"],
                humidity=row["humidity"],
                air_quality=row["air_quality"],
            )
            for _, row in df.iterrows()
        ]
        db.add_all(data_to_insert)
        db.commit()
        rows_inserted = len(data_to_insert)

        return {"message": "‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!", "rows_inserted": rows_inserted}

    except Exception as e:
        return {"error": f"‚ùå ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {str(e)}"}
    


@app.get("/sensor/aggregated")
def get_aggregated_data(
    time_window: str = Query("1h", description="‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£: ‡πÄ‡∏ä‡πà‡∏ô '10m', '1h', '24h'"),
    db: Session = Depends(get_db)
):
    print(f"üì° ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö time_window: {time_window}")  # ‚úÖ Debug

    unit = time_window[-1]
    value = int(time_window[:-1])
    if unit == "m":
        delta = timedelta(minutes=value)
    elif unit == "h":
        delta = timedelta(hours=value)
    elif unit == "d":
        delta = timedelta(days=value)
    else:
        print("‚ùå ‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á time_window ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á!")
        return {"error": "‚ùå time_window ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 10m, 1h, 24h"}

    latest_time = db.query(SensorData.timestamp).order_by(SensorData.timestamp.desc()).first()
    if not latest_time:
        print("üì≠ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Database")
        return {"message": "üì≠ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"}

    start_time = latest_time[0] - delta
    print(f"üìä ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡πà‡∏ß‡∏á: {start_time} - {latest_time[0]}")

    data = db.query(SensorData).filter(SensorData.timestamp >= start_time).all()
    if not data:
        print("üì≠ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ")
        return {"message": "üì≠ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏µ‡πâ"}

    df = pd.DataFrame([d.__dict__ for d in data])
    df.drop(columns=["_sa_instance_state"], inplace=True, errors="ignore")

    aggregated = {
        "temperature": {
            "mean": df["temperature"].mean(),
            "median": df["temperature"].median(),
            "min": df["temperature"].min(),
            "max": df["temperature"].max()
        },
        "humidity": {
            "mean": df["humidity"].mean(),
            "median": df["humidity"].median(),
            "min": df["humidity"].min(),
            "max": df["humidity"].max()
        },
        "air_quality": {
            "mean": df["air_quality"].mean(),
            "median": df["air_quality"].median(),
            "min": df["air_quality"].min(),
            "max": df["air_quality"].max()
        }
    }

    print(f"‚úÖ ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ: {aggregated}")  # ‚úÖ Debug
    return {"time_window": time_window, "aggregated_data": aggregated}